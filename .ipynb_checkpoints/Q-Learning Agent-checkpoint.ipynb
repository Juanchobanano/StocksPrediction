{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning Agent \n",
    "---\n",
    "En este notebook se desarrolla un agente de Q-Learning que aprende a escapar de un pequeño laberinto. Para ello, se diseña un pequeño grid que recrea el puzzle de donde debe escapar, el cual incorpora una meta y un punto de \"game over\". Adicionalmente, se explora el diseño, testeo y optimización de políticas del agente. Para lograr el objetivo anterior, se definen algunas de las variables del agente de Q-Learning:\n",
    "\n",
    "**1. Ambiente:** El ambiente corresponde al laberinto en donde se encuentra el agente. Este laberinto consistirá en un grid de tamaño 4x3, el cual incorporá un punto de llegada y un punto de \"game over\". Adicionalmente, una de las casillas del grid será innacesible (o lo que es lo mismo, tendrá un muro).\n",
    "\n",
    "**2. Estados:** Los estados del agente corresponderán a la posición (coordenadas) en donde se encuentre. Por ejemplo, el estado del agente en el momento $t$ es $S_{t} = (1, 2)$.\n",
    "\n",
    "**3. Acciones:** Las acciones que puede tomar el agente son: Arriba ($up$), Abajo ($down$), Derecha ($right$), Izquierda ($left$). En caso en que el agente se \"estrelle con un muro\", el robot vuelve al estado en donde estaba.\n",
    "\n",
    "**4. Recompensas:** Para el caso del agente en el laberinto, se incluirá una \"penalidad de vida\", es decir, cada vez que el agente tome una acción, recibirá una recompensa constante $r$. Si llega a la meta, recibirá una recompensa $R_{win}$ y se pierde $R_{loss}$\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/725/1*NyWUkwz1QhrVJj9ygCQ5nA.png\" alt=\"Smiley face\" height=\"300\" width=\"450\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def clear():\n",
    "    os.system( 'cls' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set walls and paths.\n",
    "walls_and_paths = [[1, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 0], [1, 0, 1, 1, 1], [1, 0, 1, 1, 1]]\n",
    "\n",
    "\n",
    "# Set rewards.\n",
    "rw = -1\n",
    "rewards = [[0, rw, rw, rw, rw], [rw, rw, rw, rw, rw], [rw, rw, rw, rw, rw], [rw, rw, rw, rw, rw], [rw, rw, rw, -10, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_grid(x, y, value_state_table):\n",
    "\n",
    "        grid_pos = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    \n",
    "        fig1 = plt.figure(figsize=(4, 4))\n",
    "        ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "\n",
    "        # Horizontal lines.\n",
    "        for i in range(0, 6):\n",
    "            ax1.axhline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "            ax1.axvline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "\n",
    "        # Salida, Meta & GameOver.\n",
    "        ax1.add_patch(patches.Rectangle((0.0, 0.0), 0.2, 0.2, facecolor = \"#F6D924\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.8), 0.2, 0.2, facecolor = \"#68FF33\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.6), 0.2, 0.2, facecolor = \"#FF5533\"))\n",
    "\n",
    "        # Muros del juego.\n",
    "        ax1.add_patch(patches.Rectangle((0.2, 0.4), 0.2, 0.4, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.6, 0.2), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.2, 0.0), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.2), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.4, 0.8), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "\n",
    "        # Limit grid view.\n",
    "        plt.ylim((0, 1))\n",
    "        plt.xlim((0, 1))\n",
    "\n",
    "        # Plot text reward.\n",
    "        pos_correct = -.02\n",
    "        #plt.text(0.9 + pos_correct, 0.9 + pos_correct, \"1\", fontsize=16)\n",
    "        #plt.text(0.9 + pos_correct, 0.7 + pos_correct, \"-1\", fontsize=16)\n",
    "        plt.scatter(x, y, s = 100, color = \"black\", marker = \"x\", edgecolors = \"black\", zorder = 10)\n",
    "\n",
    "        # Plot state values.\n",
    "        for i in range(0, len(value_state_table)):\n",
    "            for j in range(0, len(value_state_table[0])):\n",
    "                plt.text(grid_pos[i] - 0.02, grid_pos[j] - 0.03, value_state_table[i][j], fontsize=16)\n",
    "                \n",
    "        # Plot grid.\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random agent.\n",
    "class randomAgent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pos = [0, 0]\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "        self.living_penalty = -1\n",
    "        self.total_reward = 0\n",
    "        \n",
    "    def selectAction(self):\n",
    "        action = self.actions[random.randint(0, 3)]\n",
    "        return action \n",
    "    \n",
    "    def move(self):\n",
    "        act = self.selectAction()\n",
    "        previous_pos = self.pos.copy()\n",
    "        self.total_reward += self.living_penalty\n",
    "        \n",
    "        print(\"Action taken: \", act)\n",
    "        \n",
    "        try:\n",
    "            if(act == \"up\" and self.pos[1] < 4):\n",
    "                \n",
    "                if(walls_and_paths[self.pos[0]][self.pos[1] + 1]) == 1:\n",
    "                    self.pos = [self.pos[0], self.pos[1] + 1]\n",
    "\n",
    "            elif(act == \"down\" and self.pos[1] > 0):\n",
    "\n",
    "                if(walls_and_paths[self.pos[0]][self.pos[1] - 1]) == 1:\n",
    "                    self.pos = [self.pos[0], self.pos[1] - 1]\n",
    "\n",
    "            elif(act == \"left\" and self.pos[0] > 0):\n",
    "\n",
    "                if(walls_and_paths[self.pos[0] - 1][self.pos[1]]) == 1:\n",
    "                    self.pos = [self.pos[0] - 1, self.pos[1]]\n",
    "\n",
    "            elif(act == \"right\" and self.pos[0] < 4):\n",
    "                if(walls_and_paths[self.pos[0] + 1][self.pos[1]]) == 1:\n",
    "                    self.pos = [self.pos[0] + 1, self.pos[1]]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def getPos(self):\n",
    "        return self.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class valueBasedAgent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pos = [0, 0]\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.delta = 0\n",
    "        self.sigma = 20\n",
    "        self.living_penalty = -1\n",
    "        self.value_state_table = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "        \n",
    "    def valueFunction(self, state):\n",
    "        \n",
    "        prob = 0.25\n",
    "        learning_rate = 0.3\n",
    "        state_value = 0\n",
    "        \n",
    "        for a in self.actions: \n",
    "            \n",
    "            new_states = self.computeNewStates(state)\n",
    "            expected_return = 0\n",
    "            \n",
    "            for s in new_states:\n",
    "                expected_return += (rewards[s[0]][s[1]]) # + learning_rate * self.valueFunction(s))\n",
    "            state_value += prob * expected_return \n",
    "        \n",
    "        return state_value\n",
    "    \n",
    "    \n",
    "    def computeNewStates(self, state):\n",
    "        \n",
    "        \n",
    "        can_go_up = (walls_and_paths[self.pos[0]][self.pos[1] + 1] == 1) and ((state[1] + 1) > 4)\n",
    "        if can_go_up: \n",
    "            up = [state[0], state[1] + 1] \n",
    "        else: \n",
    "            up = state\n",
    "        \n",
    "        can_go_down = (walls_and_paths[self.pos[0]][self.pos[1] - 1] == 1) and ((state[1] - 1) > 0)\n",
    "        if can_go_down: \n",
    "            down = [state[0], state[1] - 1] \n",
    "        else: \n",
    "            down = state\n",
    "                \n",
    "        can_go_left = (walls_and_paths[self.pos[0] - 1][self.pos[1]] == 1) and ((state[0] - 1) > 0)\n",
    "        if can_go_left: \n",
    "            left = [state[0] - 1, state[1]] \n",
    "        else: \n",
    "            left = state\n",
    "                \n",
    "        can_go_right = (walls_and_paths[self.pos[0] + 1][self.pos[1]] == 1) and ((state[0] + 1) < 4)\n",
    "        if can_go_right: \n",
    "            right = [state[0] + 1, state[1]] \n",
    "        else: \n",
    "            right = state\n",
    "        \n",
    "        return [up, down, left, right]\n",
    "        \n",
    "        \n",
    "    def updateValueStateTable(self, value_state_table, state = [0, 0]):\n",
    "        \n",
    "        new_table = value_state_table\n",
    "        new_state_value = self.valueFunction(state)\n",
    "        new_table[state[0]][state[1]] = new_state_value\n",
    "        return new_table\n",
    "        \n",
    "    def selectAction(self):\n",
    "        action = self.actions[random.randint(0, 3)]\n",
    "        return action \n",
    "    \n",
    "    def move(self):\n",
    "        \n",
    "        # Select action.\n",
    "        act = self.selectAction()\n",
    "        print(\"Action taken: \", act)\n",
    "        \n",
    "        # Give living penalty reward.\n",
    "        #self.giveReward(self.living_penalty)\n",
    "        \n",
    "        # Update the Value State Table.\n",
    "        self.value_state_table = self.updateValueStateTable(self.value_state_table, state = self.pos)\n",
    "        \n",
    "        # Move the player.\n",
    "        try:\n",
    "            if(act == \"up\" and self.pos[1] < 4):\n",
    "                \n",
    "                if(walls_and_paths[self.pos[0]][self.pos[1] + 1]) == 1:\n",
    "                    self.pos = [self.pos[0], self.pos[1] + 1]\n",
    "\n",
    "            elif(act == \"down\" and self.pos[1] > 0):\n",
    "\n",
    "                if(walls_and_paths[self.pos[0]][self.pos[1] - 1]) == 1:\n",
    "                    self.pos = [self.pos[0], self.pos[1] - 1]\n",
    "\n",
    "            elif(act == \"left\" and self.pos[0] > 0):\n",
    "\n",
    "                if(walls_and_paths[self.pos[0] - 1][self.pos[1]]) == 1:\n",
    "                    self.pos = [self.pos[0] - 1, self.pos[1]]\n",
    "\n",
    "            elif(act == \"right\" and self.pos[0] < 4):\n",
    "                if(walls_and_paths[self.pos[0] + 1][self.pos[1]]) == 1:\n",
    "                    self.pos = [self.pos[0] + 1, self.pos[1]]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def getPos(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def getTotalReward(self):\n",
    "        return self.total_reward\n",
    "    \n",
    "    def giveReward(self, points):\n",
    "        self.total_reward += points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Action taken:  up\n",
      "Position:  ( 4 , 3 )\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid_pos = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "agent = randomAgent()\n",
    "pos = agent.getPos()\n",
    "#print(\"Position: \", pos[0], pos[1])\n",
    "draw_grid(pos[0] + 0.1, pos[1] + 0.1)\n",
    "\n",
    "while not ((pos[0] == 4 and pos[1] == 4) or (pos[0] == 4 and pos[1] == 3)):\n",
    "    print(\"------\")\n",
    "    agent.move()\n",
    "    pos = agent.getPos()\n",
    "    \n",
    "    print(\"Position: \", \"(\", pos[0], \",\", pos[1], \")\")\n",
    "    draw_grid(grid_pos[pos[0]], grid_pos[pos[1]])\n",
    "    time.sleep(0.1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Based Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Action taken:  left\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2dc2f24d3a2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetPos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a1cc1da5658>\u001b[0m in \u001b[0;36mmove\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;31m# Update the Value State Table.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_state_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdateValueStateTable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_state_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# Move the player.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a1cc1da5658>\u001b[0m in \u001b[0;36mupdateValueStateTable\u001b[1;34m(self, value_state_table, state)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mnew_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_state_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mnew_state_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalueFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[0mnew_table\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a1cc1da5658>\u001b[0m in \u001b[0;36mvalueFunction\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mnew_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomputeNewStates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mexpected_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-3a1cc1da5658>\u001b[0m in \u001b[0;36mcomputeNewStates\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mcan_go_up\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwalls_and_paths\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcan_go_up\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "grid_pos = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "agent = valueBasedAgent()\n",
    "pos = agent.getPos()\n",
    "#print(\"Position: \", pos[0], pos[1])\n",
    "draw_grid(pos[0] + 0.1, pos[1] + 0.1, agent.value_state_table)\n",
    "\n",
    "while not ((pos[0] == 4 and pos[1] == 4) or (pos[0] == 4 and pos[1] == 3)):\n",
    "    print(\"------\")\n",
    "    agent.move()\n",
    "    pos = agent.getPos()\n",
    "    \n",
    "    print(\"Position: \", \"(\", pos[0], \",\", pos[1], \")\")\n",
    "    draw_grid(grid_pos[pos[0]], grid_pos[pos[1]], agent.value_state_table)\n",
    "    time.sleep(0.1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sys.getrecursionlimit>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getrecursionlimit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.setrecursionlimit(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid World characteristics.\n",
    "class GridWorld():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Grid walls and paths.\n",
    "        self.walls_and_paths = [[1, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 0], [1, 0, 1, 1, 1], [1, 0, 1, 1, 1]\n",
    "        \n",
    "        # Value State table.\n",
    "        self.value_state_table = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "        \n",
    "        # Initialize random agent.\n",
    "        self.agent = randomAgent()\n",
    "                                \n",
    "    # Dynaminc Programming.\n",
    "    def stateValue(self):\n",
    "        \n",
    "        return \"\"\n",
    "    \n",
    "    def actionStateValue(self):\n",
    "        return \"\"\n",
    " \n",
    "    # Draw Grid.\n",
    "    def draw_grid(x, y):\n",
    "\n",
    "        fig1 = plt.figure(figsize=(4, 4))\n",
    "        ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "\n",
    "        # Horizontal lines.\n",
    "        for i in range(0, 6):\n",
    "            ax1.axhline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "            ax1.axvline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "\n",
    "        # Salida, Meta & GameOver.\n",
    "        ax1.add_patch(patches.Rectangle((0.0, 0.0), 0.2, 0.2, facecolor = \"#F6D924\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.8), 0.2, 0.2, facecolor = \"#68FF33\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.6), 0.2, 0.2, facecolor = \"#FF5533\"))\n",
    "\n",
    "        # Muros del juego.\n",
    "        ax1.add_patch(patches.Rectangle((0.2, 0.4), 0.2, 0.4, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.6, 0.2), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.2, 0.0), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.2), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.4, 0.8), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "\n",
    "        # Limit grid view.\n",
    "        plt.ylim((0, 1))\n",
    "        plt.xlim((0, 1))\n",
    "\n",
    "        # Plot text reward.\n",
    "        pos_correct = -.02\n",
    "        plt.text(0.9 + pos_correct, 0.9 + pos_correct, \"1\", fontsize=16)\n",
    "        plt.text(0.9 + pos_correct, 0.7 + pos_correct, \"-1\", fontsize=16)\n",
    "        plt.scatter(x, y, s = 100, color = \"black\", marker = \"x\", edgecolors = \"black\", zorder = 10)\n",
    "\n",
    "        # Plot grid.\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "                 \n",
    "# Initialize GridWorld obj.\n",
    "gridworld = GridWorld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld():\n",
    "    \n",
    "    def __init__(width = 5, height = 5, living_penalty = 0):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "        # Value State table.\n",
    "        value_state_table = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "        \n",
    "        # State value matrix.\n",
    "        \"\"\"\n",
    "        state_matrix = list()\n",
    "        for i in range(0, height):\n",
    "            row_values = list()\n",
    "    \n",
    "            for j in range(0, width):\n",
    "                row_values.append(self.living_penalty)\n",
    "            state_matrix.append(row_values)\n",
    "        \n",
    "        # Action State value matrix.\n",
    "        action_state_matrix = list()\n",
    "        for i in range(0, height):\n",
    "            row_values = list()\n",
    "            for j in range(0, width):\n",
    "                state_q_values = list()\n",
    "                \n",
    "                for k in range(0, 4):\n",
    "                    state_q_values.append(0)\n",
    "                    \n",
    "                row_values.append(state_q_values)\n",
    "            action_state_matrix.append(row_values)\n",
    "        \"\"\"\n",
    "                    \n",
    "    def stateValue():\n",
    "        return \"\"\n",
    "    \n",
    "    def actionStateValue():\n",
    "        return \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
