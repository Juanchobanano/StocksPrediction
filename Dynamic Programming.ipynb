{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming Introduction.\n",
    "\n",
    "---\n",
    "\n",
    "I highly recommend to visit David Silver Lectures on Planning by Dynamic Programming: https://www.youtube.com/watch?v=Nd1-UUMVfz4\n",
    "\n",
    "**Dynamic Programming** is a very general solution method for problems which have two properties:\n",
    "1. Optimal substructure, i.e, Principle of optimality applies and optimal solution can be decomposed into subproblems. \n",
    "2. Overlapping subproblems, i.e, subproblems recur many times and solutions can be cached and reused. \n",
    "Fortunately, Markov decision processes satisfy both properties: Bellman equation gives recursive decomposition and value function stores a reuses solutions.\n",
    "\n",
    "The esence of dynamic programming is based on the fact that we have full knowledge of the MDP, which we will use for planning. But, what does full knowledge means? It means we can completely characterize all the states, actions, transition probabilities and reward function of the stochastic process. This is an extremely weird case when developing IA in practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graphics():\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Graphics module ready!\")\n",
    "        \n",
    "    def render(self, x, y, environment, plot_values = True):\n",
    "            \n",
    "        fig1 = plt.figure(figsize=(4, 4))\n",
    "        ax1 = fig1.add_subplot(111, aspect='equal')\n",
    "\n",
    "        # Horizontal lines.\n",
    "        for i in range(0, 6):\n",
    "            ax1.axhline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "            ax1.axvline(i * 0.2, linewidth=2, color=\"#2D2D33\")\n",
    "\n",
    "        # Salida, Meta & GameOver.\n",
    "        ax1.add_patch(patches.Rectangle((0.0, 0.0), 0.2, 0.2, facecolor = \"#F6D924\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.6), 0.2, 0.2, facecolor = \"#68FF33\"))\n",
    "        #ax1.add_patch(patches.Rectangle((0.8, 0.8), 0.2, 0.2, facecolor = \"#FF5533\"))\n",
    "        \n",
    "        # Muros del juego.\n",
    "        ax1.add_patch(patches.Rectangle((0.2, 0.4), 0.2, 0.4, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.6, 0.2), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.2, 0.0), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        \n",
    "        ax1.add_patch(patches.Rectangle((0.4, 0.8), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.4, 0.8), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        ax1.add_patch(patches.Rectangle((0.8, 0.4), 0.2, 0.2, facecolor = \"#33A4FF\"))\n",
    "        \n",
    "        # Limit grid view.\n",
    "        plt.ylim((0, 1))\n",
    "        plt.xlim((0, 1))\n",
    "\n",
    "        # Plot player.\n",
    "        plt.scatter(x, y, s = 100, color = \"black\", marker = \"o\", facecolor = \"blue\", edgecolors = \"blue\", zorder = 10)\n",
    "\n",
    "        # Plot state values.\n",
    "        if plot_values:\n",
    "            for i in range(0, len(environment.value_state_table)):\n",
    "                for j in range(0, len(environment.value_state_table[0])):\n",
    "                    plt.text(environment.grid_pos[i] - 0.08, environment.grid_pos[j] - 0.03, \n",
    "                             round(environment.value_state_table[i][j], 2), fontsize=16)\n",
    "                \n",
    "        # Plot grid.\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridEnvironment():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.rw = -1 # Living (Movement) Penalty\n",
    "        self.walls_and_paths = [[1, 1, 1, 1, 1], [0, 1, 0, 0, 1], [1, 1, 1, 1, 0], [1, 0, 1, 1, 1], [1, 1, 0, 1, 1]]\n",
    "        self.rewards = [[self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw], \n",
    "                        [self.rw, self.rw, self.rw, self.rw, self.rw]]\n",
    "        self.grid_pos = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "        self.value_state_table = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 100, 0]]\n",
    "        \n",
    "    def getStateValue(self, position):\n",
    "        return self.value_state_table[position[0]][position[1]]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.value_state_table = [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 100, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphics module ready!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAVSUlEQVR4nO3de1Bc12HH8e/Rwmph0QOK9bAEFhJCinBwijWuHE1jm0zrRBnDjO3YaW3VdWKN6kwcJR43zqjOqw9lXHcka9wZVVUax1XU1M8MJGnitEZJWk0UV0I1EUQSLxmM5UgYhMQKltftHxgc2OWRy5J7juf3+cfjsxf2t0f3dx8LezCe5yEi9pkXdAARSU7lFLGUyiliKZVTxFIqp4il0qZ6sKRko97KFZljtbXHTLLxKcs51RfaZvRA4kLe0azhR48FHWVG+h/fCLg1ty5khalPgLqsFbGUyiliKZVTxFIqp4ilVE4RS6mcIpZSOUUspXKKWErlFLGUyiliKZVTxFIqp4ilVE4RS6mcIpZSOUUs5bucxpg8Y8wLxphuY8wlY8xLxpj8VIZLFZeyAvS/3UbT3js5sW0RJx5YSNOTt9Pf0Rp0rKRcm1uX8voqpzEmE6gG1gP3AVuBtcBhY0w0dfFmz6WsAMPxK5zZVUbfuVMUbH+GggcP0vdWA6d33cJQXyzoeOO4Nreu5Z12JYRJbANWA+s8z2sEMMbUAg3AdmB3auKlhEtZuXD4APHzzRQ/cZrIskIAMvJKOPnIWjqq97N0y8MBJxzHqbnFsbx+L2vLgaOjLxDA87wW4AhQkYpgKeRSVrprqogWbhorJsD8JQVkFW3mYk1lgMmScmpucSyv33IWAyeTjNcBG/zHmRMuZaW3vY6MldcmjGesKKavvT6ARFNyam5xLK/fcuYAXUnGO4Fs/3HmhEtZGerpJBRNjBXKymEwluxlBMqpucWxvLP5UUqyVcNsXfHMpawYkySavX9wyqm5xaG8fsvZxchRaKJskh+ZguRSVkLRbAZ7OhPGh2JdpCU5owbMqbnFsbx+y1nHyPX7RBsA226MXMpKxspietvrEsZ72+uJrLDutsipucWxvH7LWQVsMsasHh0wxqwCNr/zmE1cysqi0nJijUeJn28eG4tfOEtPwxEWl5YHmCwpp+YWx/L6LecB4CxQaYypMMaUA5VAG7A/RdlSxaWs5N68jfm5q2jcXcHF45VcPF5F054Kwjl55JZtDzreRE7NLY7l9VVOz/NiQBlwBjgIHAJagDLP83pSF2/2XMoKEIpEKdpZTWR5ES37ttKy7x7CVxVQtLOaUCQr6HjjuDa3ruX1+xtCeJ7XCtyRwixzxqWsAOHcfNbseDHoGDPi2ty6lFefShGxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpVROEUsZb4q1aUpKNlq7cI3Ie0Vt7bGkaxjpzCliqWk/zzlZq20zepYPP3os6CjT6n98I+De3LqQdzTr5tqgk8zMkZLJH9OZU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlO9yGmPyjDEvGGO6jTGXjDEvGWPyUxkuVfrfbqNp752c2LaIEw8spOnJ2+nvaA061qRcmluXsva80c//PNTKd288xTcya/gnc5xLZ+MJ2w32DfPzv3yDf13+Ggcyavjujad482eXE7bzhj1qvn6Ob6/6JQciNTx/XT3NL3alLK+vchpjMoFqYD1wH7AVWAscNsZEU5YuBYbjVzizq4y+c6co2P4MBQ8epO+tBk7vuoWhvljQ8RK4NLcuZQXobozT9FwX4ewQy/5wwaTb/eRTr/OrAx1s/Our+ej3C8lcns4Pbm2g4/+ujNvu1S+9ybGvnuPaz1zFlh+uZcmmKD/+eDOv/0d3SvL6/cvW24DVwDrP8xoBjDG1QAOwHdidknQpcOHwAeLnmyl+4jSRZYUAZOSVcPKRtXRU72fplocDTpjAmbnFraxc/aEs7vv1dQD86hsdvPHjSwnbdLx2hcZ/6+Tmb17D+vtzR77upgU8W1zH/375TT5aNbIP9Z4f4LV/+DW//8VlfOCRZQCsuGUBlxrj/OKL7VyzZdGs8/q9rC0Hjo7+gwB4ntcCHAEqZp0qhbprqogWbhorJsD8JQVkFW3mYk1lgMkm5czc4lZWzLzpV1l5vaqbeemGNXfnjI3NSzMUfiKHtpcvMRQfBqDt5UsM93usvTdn3NevvTeHzl/2cqkl8XL5t+W3nMXAySTjdcAG/3FSr7e9joyV1yaMZ6wopq+9PoBE03JmbnEr64x01vWyoCBMeub4amQXRxju9+hujI9tF5pvWFQ4f8J2GQB01ffNOovfcuYAye58O4Fs/3FSb6ink1A0MVIoK4fBWOpu3lPImbnFrawzEu8cZH524t1eJCdt7PGR/w4RXhzCGDNhu9C47WZjNj9KSbamrZWrs02cQACmWK/XAs7MLW5lnZbnwUx2l5luNxt+y9nFyFFzomySH0kDE4pmM9jTmTA+FOsiLckZ1QLOzC1uZZ2RSE4afUnOevGukbH575xBIzkh4l1DTFyUPd41NG672fBbzjpG7jcm2gBYdSOXsbKY3va6hPHe9noiK6y8LXJmbnEr64xkF0e43NLPwJXhceNd9X3MC797j5ldnMFQ3ONSU3zCdr0jj2+IzDqL33JWAZuMMatHB4wxq4DN7zxmjUWl5cQajxI/3zw2Fr9wlp6GIywuLQ8w2aScmVvcyjojq8oXMzzg0fz8uyf+4UGPpme7yPvjhYTmj1Qm/yMLmRc2NBwaf1XW8O1Ocq6NsLBg/BtFfvg99x4APgNUGmMeY+S+42+ANmD/rFOlUO7N27jw43+kcXcFKz7+t4DhzRe/RDgnj9yy7UHHS8aZucWtrAA0vTBSugvHR34Bpe2Hl4hclUbGVWlcfdMCcj+QyZq7sznyuTaGBzwWFISp33eByy1xPnyoYOz7ZCxJp+TzSzjx9bdIXxAitzSTpmc7aa++zEcq16Qkq69yep4XM8aUAXuAg4y8AfAK8DnP83pSkixFQpEoRTuraTv0eVr2bQU8FhR/mLx7nyQUyQo6XgKX5talrKP+8+PN4/7/vz898mucy2/KouIn6wC45elVvPpX7bz6WDv9F4f4vesy2PKjtVxVmjnua2/4uxWkZ4X45d7zXHlrgMXrIvzRc6tZddvilGT1fdfqeV4rcEdKUsyxcG4+a3a8GHSMGXNpbl3KCvAX3vXTbpOWMY8P7s7jg7vzptxuXshw/WPLuf6x5amKN/77z8l3FZFZUzlFLKVyilhK5RSxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlJn4Se7fVFKy0eq1PETeC2prjyVd1kVnThFLTfuRsclabZvRs3z40WNBR5lW/+MbAffm1oW8Lu0H8O6+kIzOnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpXyX0xiTZ4x5wRjTbYy5ZIx5yRiTn8pwqdL/dhtNe+/kxLZFnHhgIU1P3k5/R2vQsSbl0ty6lBXc2hd8ldMYkwlUA+uB+4CtwFrgsDEmmrp4szccv8KZXWX0nTtFwfZnKHjwIH1vNXB61y0M9cWCjpfApbl1KSu4ty/4/eO524DVwDrP8xoBjDG1QAOwHdidmnizd+HwAeLnmyl+4jSRZYUAZOSVcPKRtXRU72fplocDTpjAmbnFrazO7Qt+L2vLgaOj/yAAnue1AEeAilQES5XumiqihZvG/jEA5i8pIKtoMxdrKgNMNiln5ha3sjq3L/gtZzFwMsl4HbDBf5zU622vI2PltQnjGSuK6WuvDyDRtJyZW9zK6ty+4LecOUBXkvFOINt/nNQb6ukkFE2MFMrKYTCW7CUEzpm5xa2szu0Ls/lRSrI1ba1cnc2YJLGmWK/XAs7MLW5ldWpf8FvOLkaOmhNlk/xIGphQNJvBns6E8aFYF2lJjqIWcGZucSurc/uC33LWMXK/MdEGwKqL94yVxfS21yWM97bXE1lh3W0RODS3uJXVuX3BbzmrgE3GmNWjA8aYVcDmdx6zxqLScmKNR4mfbx4bi184S0/DERaXlgeYbFLOzC1uZXVuX/BbzgPAWaDSGFNhjCkHKoE2YH+KsqVE7s3bmJ+7isbdFVw8XsnF41U07akgnJNHbtn2oOMl48zc4lZW5/YFX+X0PC8GlAFngIPAIaAFKPM8ryd18WYvFIlStLOayPIiWvZtpWXfPYSvKqBoZzWhSFbQ8RK4NLcuZQX39gW/vyGE53mtwB0pzDJnwrn5rNnxYtAxZsyluXUpK7i1L+hTKSKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlMopYinjTbF+SknJRjsXVxF5D6mtPZZ0zSWdOUUsNe3nOSdrtW1Gz/Iu5HUpK7ybN/zosaCjTKv/8Y2Ae3ObjM6cIpZSOUUspXKKWErlFLGUyiliKZVTxFIqp4ilVE4RS6mcIpZSOUUspXKKWErlFLGUyiliKZVTxFIqp4ilfJfTGJNnjHnBGNNtjLlkjHnJGJOfynCp4lJWcCtv/9ttNO29kxPbFnHigYU0PXk7/R2tQcealEtz66ucxphMoBpYD9wHbAXWAoeNMdHUxZs9l7KCW3mH41c4s6uMvnOnKNj+DAUPHqTvrQZO77qFob5Y0PESuDS34P8vW28DVgPrPM9rBDDG1AINwHZgd2ripYRLWcGhvBcOHyB+vpniJ04TWVYIQEZeCScfWUtH9X6Wbnk44IQJnJlb8H9ZWw4cHX2BAJ7ntQBHgIpUBEshl7KCQ3m7a6qIFm4aKybA/CUFZBVt5mJNZYDJJuXM3IL/chYDJ5OM1wEb/MeZEy5lBYfy9rbXkbHy2oTxjBXF9LXXB5BoWs7MLfgvZw7QlWS8E8j2H2dOuJQVHMo71NNJKJoYKZSVw2As2UsInDNzC7P7UUqyVcNsXfHMpazgUF5jksSaYi1kCzgzt37L2cXIUWiibJIfmYLkUlZwKG8oms1gT2fC+FCsi7QkZ1QLODO34L+cdYxcv0+0AbDtZsOlrOBQ3oyVxfS21yWM97bXE1lh3S0cODS34L+cVcAmY8zq0QFjzCpg8zuP2cSlrOBQ3kWl5cQajxI/3zw2Fr9wlp6GIywuLQ8w2aScmVvwX84DwFmg0hhTYYwpByqBNmB/irKliktZwaG8uTdvY37uKhp3V3DxeCUXj1fRtKeCcE4euWXbg46XjDNzCz7L6XleDCgDzgAHgUNAC1DmeV5P6uLNnktZwa28oUiUop3VRJYX0bJvKy377iF8VQFFO6sJRbKCjpfApbkF/78hhOd5rcAdKcwyZ1zKCm7lDefms2bHi0HHmDGX5lafShGxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpYw3xZISJSUbrV5vQuS9oLb2WNJlUnTmFLHUtB8Z+8UL3b+LHLP2B3cuAiD86LGAk0yv//GNwORHTNuMXkG5kNelrDD11anOnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpXyX841zA/zpZ8+x7PpmlpY28YnPnKPtzYFJt29uzWfHV7/C0tIaoutPs7S0hh1f/QrNrfl+I8xY/9ttNO29kxPbFnHigYU0PXk7/R2tc/68fhlj8owxLxhjuo0xl4wxLxlj5n6ifHApK7iV11c5r/QO89H73uRM8wD//PgSvvH3S2l6fYCP/Fk7sSvDCdu//NMPcUP59/jW83dxObYAz5vH5dgCvvX8XdxQ/j1e/umHZv1CJjMcv8KZXWX0nTtFwfZnKHjwIH1vNXB61y0M9cXm7Hn9MsZkAtXAeuA+YCuwFjhsjIkGmW0il7KCe3l9/fHcp5+7REvbAK/9KJ8114QBeP+6+bz/1tf5l2e7+ez92WPbNrfmc8+Op7jSm5nwfQYGwwwMhrlnx1O8WnUbq/NTfza7cPgA8fPNFD9xmsiyQgAy8ko4+chaOqr3s3TLwyl/zlnaBqwG1nme1whgjKkFGoDtwO4As03kUlZwLK+vM+cPqmPccF1krJgAq/LSubE0wvdfGX822vvN+xkYmPoYMDCQxlPfut9PlGl111QRLdw0VkyA+UsKyCrazMWayjl5zlkqB46O7jwAnue1AEeAisBSJedSVnAsr69y1jf2s6EonDD+vsIwpxr7x439e1UFA4OJ2/6mgcEw36mcm7npba8jY+W1CeMZK4rpa6+fk+ecpWLgZJLxOmDD7zjLdFzKCo7l9VXOru4hshcmfmn2ohBdl8bfc/Zcmdml/OXY3FzyD/V0EopmJ4yHsnIYjHXNyXPOUg6QLFgnkPhCguVSVnAsr+93a02Stc2SLSOWlTmzN10WROfuzRmTNKzVS/ImC2franIuZQWH8voqZ/bCEJ3die/KXkxyRv1EeSXpaf0J2/6m9LR+/qRibu7/QtFsBns6E8aHYl2kJTmjWqCLkSP8RNkkP+oHyaWs4FheX+V8X2GYXzUkFu5UUz/rC8ffX+745NOkpw9O+f3S0wd56M+f9hNlWhkri+ltr0sY722vJ7LCutsMGLn/KU4yvgGw7SbZpazgWF5f5fxYWZRXX+ujpe3dXzp4/Y0Bfl7Tx8fKxt87rs5v5dDeh8jMuJJwBk1P6ycz4wqH9j40Jz9GAVhUWk6s8Sjx881jY/ELZ+lpOMLi0vI5ec5ZqgI2GWNWjw4YY1YBm995zCYuZQXH8voq5/13LeSaFenc9elzfO+/evj+KzHu+vQ5Vi5L41N3L0rY/tabfsarVbfxybufY2HWZYwZZmHWZT5593O8WnUbt970s1m/kMnk3ryN+bmraNxdwcXjlVw8XkXTngrCOXnklm2fs+edhQPAWaDSGFNhjCkHKoE2YH+QwZJwKSs4ltfXLyFEM+fxw2eu5gtf7+CBL/waz4Obb8zkiZ25ZEWT9311fit7vvw19nz5a7MK/NsKRaIU7aym7dDnadm3FfBYUPxh8u59klAk63eaZSY8z4sZY8qAPcBBRt6seAX4nOd5PYGGm8ClrOBeXl/lBMi7Op3vPLU8lVnmTDg3nzU7Xgw6xox5ntcK3BF0jplwKSu4lVefShGxlMopYimVU8RSKqeIpVROEUupnCKWUjlFLKVyilhK5RSxlMopYimVU8RSKqeIpVROEUsZb4q1dEpKNlq90I7Ie0Ft7bGkaxhNWU4RCY4ua0UspXKKWErlFLGUyiliKZVTxFIqp4il/h8memBWzxuO/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "environment = GridEnvironment()\n",
    "graph = Graphics()\n",
    "graph.render(0.1, 0.1, environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class valueBasedAgent():\n",
    "    \n",
    "    def __init__(self, environment, policy, discount_factor):\n",
    "        self.pos = [0,0]\n",
    "        self.total_reward = 0\n",
    "        self.environment = environment\n",
    "        self.discount_factor = discount_factor\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]\n",
    "        \n",
    "        # Start with a random policy. 0.25 chance of moving to any direction.\n",
    "        self.policy = policy   \n",
    "        \n",
    "    # Select action according to policy.\n",
    "    \"\"\"\n",
    "    def selectAction(self, state):\n",
    "        \n",
    "        if(self.policy[state[0]][state[1]] == \"r\"):\n",
    "            action = self.actions[random.randint(0, len(self.available_actions) - 1)] # Agent initial policy.\n",
    "        else: \n",
    "            action = self.policy[state[0]][state[1]]\n",
    "        return action\n",
    "    \"\"\"\n",
    "            \n",
    "    def forwardState(self, pos, action):\n",
    "        \n",
    "        # New position array.\n",
    "        new_position = pos\n",
    "        \n",
    "        # Compute new position based on action taken.\n",
    "        if(action == \"up\" and pos[1] < 4):\n",
    "            if(self.environment.walls_and_paths[pos[0]][pos[1] + 1]) == 1:\n",
    "                new_position = [pos[0], pos[1] + 1]\n",
    "\n",
    "        elif(action == \"down\" and pos[1] > 0):\n",
    "            if(self.environment.walls_and_paths[pos[0]][pos[1] - 1]) == 1:\n",
    "                new_position = [pos[0], pos[1] - 1]\n",
    "        elif(action == \"left\" and pos[0] > 0):\n",
    "            if(self.environment.walls_and_paths[pos[0] - 1][pos[1]]) == 1:\n",
    "                new_position = [pos[0] - 1, pos[1]]\n",
    "\n",
    "        elif(action == \"right\" and pos[0] < 4):\n",
    "            if(self.environment.walls_and_paths[pos[0] + 1][pos[1]]) == 1:\n",
    "                new_position = [pos[0] + 1, pos[1]]\n",
    "        return new_position\n",
    "        \n",
    "        \n",
    "    def valueFunction(self):\n",
    "            \n",
    "        # Initialize variable.\n",
    "        new_state_value = 0\n",
    "    \n",
    "        # Random movement!\n",
    "        if self.policy[self.pos[0]][self.pos[1]] == \"r\":\n",
    "            for action in self.actions:        \n",
    "                forward_state = self.forwardState(self.pos, action)\n",
    "                expected_return = (self.environment.rewards[forward_state[0]][forward_state[1]] \n",
    "                                    + self.discount_factor * self.environment.value_state_table[forward_state[0]][forward_state[1]])\n",
    "                new_state_value += expected_return * 0.25\n",
    "            return new_state_value\n",
    "        \n",
    "        # Not random movement!\n",
    "        else: \n",
    "            action = self.policy[self.pos[0]][self.pos[1]]\n",
    "            forward_state = self.forwardState(self.pos, action)\n",
    "            expected_return = (self.environment.rewards[forward_state[0]][forward_state[1]] \n",
    "                                    + self.discount_factor * self.environment.value_state_table[forward_state[0]][forward_state[1]])\n",
    "            new_state_value += expected_return\n",
    "            return new_state_value\n",
    "        \n",
    "    def getPosition(self):\n",
    "        return self.pos\n",
    "    \n",
    "    def getReward(self):\n",
    "        return self.total_reward\n",
    "    \n",
    "    def setPosition(self, x, y):\n",
    "        self.pos = [x, y]\n",
    "        \n",
    "    def updateValueStateTable(self):\n",
    "        new_state_value = self.valueFunction()\n",
    "        self.environment.value_state_table[self.pos[0]][self.pos[1]] = new_state_value\n",
    "        \n",
    "    def selectBestAction(self):\n",
    "        \n",
    "        go_up = self.forwardState(self.pos, \"up\")\n",
    "        go_down = self.forwardState(self.pos, \"down\")\n",
    "        go_left = self.forwardState(self.pos, \"left\")\n",
    "        go_right = self.forwardState(self.pos, \"right\")\n",
    "        \n",
    "        up_value = self.environment.value_state_table[go_up[0]][go_up[1]]\n",
    "        down_value =  self.environment.value_state_table[go_down[0]][go_down[1]]\n",
    "        left_value =  self.environment.value_state_table[go_left[0]][go_left[1]]\n",
    "        right_value =  self.environment.value_state_table[go_right[0]][go_right[1]]\n",
    "        values = [up_value, down_value, left_value, right_value]\n",
    "        \n",
    "        best_action = self.actions[values.index(max(values))] \n",
    "        return best_action       \n",
    "            \n",
    "    def move(self):\n",
    "    \n",
    "        # Select action according to policy.\n",
    "        action = self.policy[self.pos[0]][self.pos[1]]\n",
    "        print(\"Action taken\", action)\n",
    "\n",
    "        # Move to new position according to action taken.\n",
    "        self.pos = self.forwardState(self.pos, action)\n",
    "        print(\"New Position: \", self.pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyEvaluation(Graphics):\n",
    "    \n",
    "    def __init__(self, environment, agent, iterations = 3):\n",
    "        \n",
    "        self.environment = environment       \n",
    "        self.agent = agent                     \n",
    "        #print(\"GridWorld Initialize!\")\n",
    "        self.iterations = iterations\n",
    "    \n",
    "    def evaluate(self, plot_grid = True):\n",
    "        self.DP_policy_evaluation(self.iterations, plot_grid)\n",
    "        \n",
    "    def DP_policy_evaluation(self, iterations, plot_grid):\n",
    "        \n",
    "        for k in range(0, iterations):\n",
    "        \n",
    "            for i in range(0, len(self.environment.value_state_table)):\n",
    "                for j in range(0, len(self.environment.value_state_table[0])):\n",
    "\n",
    "                    if self.environment.walls_and_paths[i][j] == 1 and self.canChangeStateValue(i, j):\n",
    "\n",
    "                        # Set agent position.\n",
    "                        self.agent.setPosition(i, j)\n",
    "                        self.agent.updateValueStateTable()\n",
    "\n",
    "                        # Method of the super class.\n",
    "                        if(plot_grid):\n",
    "                            \n",
    "                            # Render game.\n",
    "                            pos = self.agent.getPosition()\n",
    "                            grid_coords = self.environment.grid_pos\n",
    "                            \n",
    "                            self.render(grid_coords[pos[0]], grid_coords[pos[1]], self.environment, True)\n",
    "                            time.sleep(0.01)\n",
    "                            clear_output(wait = True)\n",
    "                            \n",
    "    \n",
    "\n",
    "    def canChangeStateValue(self, x, y):\n",
    "        cant_modify = bool((x == 4 and y == 3)) # or (x == 4 and y == 4))\n",
    "        \n",
    "        grid = self.environment.walls_and_paths\n",
    "        coords = list()\n",
    "        \n",
    "        # Get walls.\n",
    "        for i in range(0, len(grid)):\n",
    "            for j in range(0, len(grid[0])):\n",
    "                if grid[i][j] == 0:\n",
    "                    coords.append([i, j])\n",
    "        for c in coords: \n",
    "            if c == [x, y]:\n",
    "                cant_modify = True\n",
    "                break\n",
    "                \n",
    "        return not cant_modify\n",
    "    \n",
    "    def updatePolicy(self):\n",
    "        \n",
    "         for i in range(0, len(self.environment.value_state_table)):\n",
    "                for j in range(0, len(self.environment.value_state_table[0])):\n",
    "                    if self.environment.walls_and_paths[i][j] == 1:\n",
    "                        \n",
    "                        # Set agent position.\n",
    "                        self.agent.setPosition(i, j)\n",
    "                        best_action = self.agent.selectBestAction()\n",
    "                        self.agent.policy[i][j] = best_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Game(Graphics):\n",
    "    \n",
    "    def __init__(self, environment, agent):\n",
    "        \n",
    "        self.environment = environment       \n",
    "        self.agent = agent             \n",
    "        print(\"GridWorld Initialize!\")\n",
    "                \n",
    "    def update(self, secs):\n",
    "        \n",
    "        pos = self.agent.getPosition()\n",
    "        grid_coords = self.environment.grid_pos\n",
    "        self.render(grid_coords[pos[0]], grid_coords[pos[1]], self.environment, False)\n",
    "        time.sleep(1)\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        while not ((self.agent.pos[0] == 4 and self.agent.pos[1] == 4) or (self.agent.pos[0] == 4 and self.agent.pos[1] == 3)):\n",
    "            \n",
    "            self.agent.move()\n",
    "            pos = self.agent.getPosition()\n",
    "            self.render(grid_coords[pos[0]], grid_coords[pos[1]], self.environment, False)\n",
    "            \n",
    "            time.sleep(secs)\n",
    "            clear_output(wait = True)\n",
    "            \n",
    "        self.render(grid_coords[pos[0]], grid_coords[pos[1]], self.environment, False)\n",
    "        time.sleep(2)\n",
    "        #print(\"Yuhuu, we won the game!\")\n",
    "        clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Policy Evaluation (Prediction or Planning) for DP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the random policy.\n",
    "policy = list()\n",
    "for i in range(0, 5):\n",
    "    column = list()\n",
    "    for j in range(0, 5):\n",
    "        column.append(\"r\")\n",
    "    policy.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r'],\n",
       " ['r', 'r', 'r', 'r', 'r']]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment and agent.\n",
    "environment = GridEnvironment()\n",
    "agent = valueBasedAgent(environment, policy, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize policy evaluation class.\n",
    "policy_evaluation = PolicyEvaluation(environment, agent, iterations = 10)\n",
    "policy_evaluation.evaluate()\n",
    "policy_evaluation.updatePolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['up', 'right', 'down', 'down', 'down'],\n",
       " ['r', 'right', 'r', 'r', 'left'],\n",
       " ['up', 'up', 'up', 'right', 'r'],\n",
       " ['left', 'r', 'up', 'right', 'right'],\n",
       " ['left', 'down', 'r', 'down', 'down']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New agent policy after policy evaluation.\n",
    "agent.policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Win the Game with the previous policity evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAFL0lEQVR4nO3bMWtUeRTG4TOaCRiCfgDBRtzCYmwGFlxsBe0EBUG3tV8s8hkiyDaWdqsgKNgp2K+wMI23EVZsBD9AMETIxL1bBdn13hlxM+Yd9nnK+79hDsP85kxCZtC2bQF5jhz2AEA3cUIocUIocUIocUKolVmHo9HYn3JhwZpmMui6PjPOWT+YZv+NZBnm3Z91dWNy2KN8ld3NcVUt13O7DLNWzV6APtZCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCKHFCqEHbtr2Ho9G4/xA4EE0zGXRdtzkh1Mq8G/qqTrO/5Vc3Joc9yly7m+OqWr7ndhnm3Z/1p+awJ/k6v4/6z2xOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCDX3+5zwf7b19mS9unuj3jy4XNPttRqu79SZm8/q3O2HdeL0+4U+ts0JPd49P1+PR4/q9f0rNf2wXtUeqemH9Xp9/0o9Hj2qd8/PL/TxxQkdtt6erBdXN2tv51i10+E/ztrpsPZ2jtWLq5u19fbkwmYQJ3R4dfdGfZrO/q3v03Slml9vLGwGcUKHNw8uf7Ex/62dDuvP3y4vbAZxQofp9tqB3vctxAkdhus7B3rftxAndDhz81kNhtOZ9wyG0/rh52cLm0Gc0OHc7Yd1dLg3856jw70a/fJwYTOIEzqcOP2+Lj7ZqJW1j19s0MFwWitrH+vik42F/iOCOKHHqUsv61pzvc7eelrD49tVR/6q4fHtOnvraV1rrtepSy8X+vj+fQ9mOHH6fV24d6cu3Lvz3R/b5oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQg7Ztew9Ho3H/IXAgmmYy6Lpuc0Koud/n7Ks6zf6WX92YHPYoc+1ujqtq+Z7bZZh3mV4HVZ9fC11sTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgg1aNu293A0GvcfAgeiaSaDrus2J4RamXdDX9Vp9rf8Msy7TLNWfZ53dWNy2KPMtbs5rqrle2672JwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQatC2be/haDTuPwQORNNMBl3XbU4ItTLvhj+ebH2POf6zH6+eqKqq1Y3JIU8y3+7muKr63zHT7H+CWoZ5l2nWqtmfTm1OCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCDVo27b3cDQa9x8CB6JpJoOu6zPjBA6Pj7UQSpwQSpwQSpwQSpwQSpwQ6m9axemZDlO2KgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "positions = [[1, 4], [4, 1], [0, 0]]\n",
    "\n",
    "for p in positions: \n",
    "    agent.pos = p\n",
    "    game = Game(environment, agent)\n",
    "    game.update(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We made it! We have developed our first artificial intelligence. As you can see, we took a random policy and evaluate it through our policity evaluation algorithm, then, we encourage our agent to take the best action for each state, which lead us to an amazing result.\n",
    "\n",
    "Something that surprised me the very first time I learnt about **Dynamic Programming**, was the fact that even though we chose a random policy, it led us to a solution of the grid world problem. According to the this, how our solution could change if we would have choosen a more reasonable policy? This is the question that we are going to try to answer in the following section, through **Policity Iteration** and **Value Iteration**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Policy Iteration (Control). Improving our Policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the random policy.\n",
    "policy = list()\n",
    "for i in range(0, 5):\n",
    "    column = list()\n",
    "    for j in range(0, 5):\n",
    "        column.append(\"r\")\n",
    "    policy.append(column)\n",
    "    \n",
    "# Initaliza environment and agent.\n",
    "discount_factor = 0.5\n",
    "environment = GridEnvironment()\n",
    "agent = valueBasedAgent(environment, policy, discount_factor)\n",
    "\n",
    "# Policy iteration algorithm.\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # Reset value function.\n",
    "    environment.reset()\n",
    "\n",
    "    # Evaluate new policy.\n",
    "    policy_evaluation = PolicyEvaluation(environment, agent, iterations = 10)\n",
    "    policy_evaluation.evaluate(plot_grid = False)\n",
    "    policy_evaluation.updatePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['up', 'right', 'down', 'down', 'down'],\n",
       " ['r', 'right', 'r', 'r', 'left'],\n",
       " ['up', 'up', 'up', 'right', 'r'],\n",
       " ['left', 'r', 'up', 'right', 'down'],\n",
       " ['left', 'down', 'r', 'down', 'down']]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Value Iteration (Control). Improving our Policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the random policy.\n",
    "policy = list()\n",
    "for i in range(0, 5):\n",
    "    column = list()\n",
    "    for j in range(0, 5):\n",
    "        column.append(\"r\")\n",
    "    policy.append(column)\n",
    "    \n",
    "# Initaliza environment and agent.\n",
    "discount_factor = 1\n",
    "environment = GridEnvironment()\n",
    "agent = valueBasedAgent(environment, policy, discount_factor)\n",
    "\n",
    "# Policy iteration algorithm.\n",
    "for i in range(0, 10):\n",
    "\n",
    "    # Reset value function.\n",
    "    environment.reset()\n",
    "\n",
    "    # Evaluate new policy.\n",
    "    policy_evaluation = PolicyEvaluation(environment, agent, iterations = 2)\n",
    "    policy_evaluation.evaluate(plot_grid = False)\n",
    "    policy_evaluation.updatePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The optimal policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['down', 'down', 'down', 'down', 'down'],\n",
       " ['r', 'up', 'r', 'r', 'left'],\n",
       " ['up', 'up', 'up', 'right', 'r'],\n",
       " ['left', 'r', 'up', 'right', 'down'],\n",
       " ['left', 'down', 'r', 'down', 'down']]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
